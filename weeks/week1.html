<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>MASAR AI - Week 1: LM & Transformers</title>
<style>
    /* ==================== GENERAL STYLES ==================== */
    @import url('https://fonts.googleapis.com/css2?family=Poppins:wght@300;400;600;700&display=swap');
    
    * {
        margin: 0;
        padding: 0;
        box-sizing: border-box;
    }
    
    body {
        font-family: 'Poppins', sans-serif;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        min-height: 100vh;
        padding: 20px;
        color: #333;
    }
    
    .container {
        max-width: 1200px;
        margin: 0 auto;
        background: white;
        border-radius: 20px;
        box-shadow: 0 20px 60px rgba(0,0,0,0.3);
        overflow: hidden;
    }
    
    /* ==================== HEADER WITH PROGRESS ==================== */
    .header {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 30px;
        text-align: center;
        position: relative;
    }
    
    .header h1 {
        font-size: 2.5em;
        margin-bottom: 10px;
        text-shadow: 2px 2px 4px rgba(0,0,0,0.2);
    }
    
    .header .subtitle {
        font-size: 1.1em;
        opacity: 0.9;
    }
    
    .progress-container {
        margin-top: 20px;
        background: rgba(255,255,255,0.2);
        border-radius: 10px;
        height: 30px;
        overflow: hidden;
    }
    
    .progress-bar {
        height: 100%;
        background: linear-gradient(90deg, #48c6ef 0%, #6f86d6 100%);
        width: 0%;
        transition: width 0.5s ease;
        display: flex;
        align-items: center;
        justify-content: center;
        font-weight: bold;
        font-size: 0.9em;
    }
    
    /* ==================== GAMIFICATION STATS ==================== */
    .stats-bar {
        display: flex;
        justify-content: space-around;
        padding: 20px;
        background: #f8f9fa;
        border-bottom: 3px solid #e9ecef;
    }
    
    .stat-item {
        text-align: center;
        padding: 10px 20px;
        background: white;
        border-radius: 10px;
        box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        min-width: 120px;
    }
    
    .stat-item .stat-icon {
        font-size: 2em;
        margin-bottom: 5px;
    }
    
    .stat-item .stat-label {
        font-size: 0.85em;
        color: #6c757d;
        font-weight: 600;
    }
    
    .stat-item .stat-value {
        font-size: 1.5em;
        font-weight: bold;
        color: #667eea;
    }
    
    /* ==================== NAVIGATION TABS ==================== */
    .nav-tabs {
        display: flex;
        overflow-x: auto;
        background: #f8f9fa;
        border-bottom: 3px solid #dee2e6;
        padding: 0 10px;
    }
    
    .nav-tabs::-webkit-scrollbar {
        height: 6px;
    }
    
    .nav-tabs::-webkit-scrollbar-thumb {
        background: #667eea;
        border-radius: 3px;
    }
    
    .tab-btn {
        padding: 15px 25px;
        border: none;
        background: none;
        color: #495057;
        font-weight: 600;
        cursor: pointer;
        border-bottom: 3px solid transparent;
        transition: all 0.3s ease;
        white-space: nowrap;
        position: relative;
    }
    
    .tab-btn:hover {
        background: rgba(102, 126, 234, 0.1);
        color: #667eea;
    }
    
    .tab-btn.active {
        color: #667eea;
        border-bottom-color: #667eea;
        background: white;
    }
    
    .tab-btn .badge {
        position: absolute;
        top: 5px;
        right: 5px;
        background: #28a745;
        color: white;
        border-radius: 50%;
        width: 20px;
        height: 20px;
        font-size: 0.7em;
        display: flex;
        align-items: center;
        justify-content: center;
    }
    
    /* ==================== CONTENT SECTIONS ==================== */
    .content-section {
        display: none;
        padding: 30px;
        animation: fadeInUp 0.5s ease;
    }
    
    .content-section.active {
        display: block;
    }
    
    @keyframes fadeInUp {
        from {
            opacity: 0;
            transform: translateY(20px);
        }
        to {
            opacity: 1;
            transform: translateY(0);
        }
    }
    
    h2 {
        color: #667eea;
        margin-bottom: 20px;
        font-size: 2em;
        border-bottom: 3px solid #667eea;
        padding-bottom: 10px;
    }
    
    h3 {
        color: #764ba2;
        margin-top: 25px;
        margin-bottom: 15px;
        font-size: 1.5em;
    }

    h4 {
        color: #667eea;
        margin-top: 20px;
        margin-bottom: 10px;
        font-size: 1.2em;
    }
    
    /* ==================== GLOSSARY ACCORDION ==================== */
    .glossary-accordion {
        margin: 20px 0;
    }
    
    .accordion-item {
        margin-bottom: 10px;
        border-radius: 10px;
        overflow: hidden;
        box-shadow: 0 2px 5px rgba(0,0,0,0.1);
    }
    
    .accordion-header {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 15px 20px;
        cursor: pointer;
        display: flex;
        justify-content: space-between;
        align-items: center;
        font-weight: 600;
        transition: all 0.3s ease;
    }
    
    .accordion-header:hover {
        background: linear-gradient(135deg, #764ba2 0%, #667eea 100%);
    }
    
    .accordion-header .icon {
        transition: transform 0.3s ease;
    }
    
    .accordion-header.active .icon {
        transform: rotate(180deg);
    }
    
    .accordion-content {
        max-height: 0;
        overflow: hidden;
        transition: max-height 0.3s ease;
        background: white;
    }
    
    .accordion-content.active {
        max-height: 500px; /* Increased max-height for potentially longer content */
    }
    
    .accordion-content p, .accordion-content ul {
        padding: 20px;
        line-height: 1.6;
    }
    
    /* ==================== INFO CARDS ==================== */
    .info-card {
        background: white;
        border-radius: 15px;
        padding: 25px;
        margin: 20px 0;
        box-shadow: 0 5px 15px rgba(0,0,0,0.1);
        border-left: 5px solid #667eea;
    }
    
    .info-card.warning {
        border-left-color: #ffc107;
        background: #fff9e6;
    }
    
    .info-card.success {
        border-left-color: #28a745;
        background: #e8f5e9;
    }
    
    .info-card.danger {
        border-left-color: #dc3545;
        background: #ffebee;
    }
    
    .info-card.info {
        border-left-color: #17a2b8;
        background: #e3f2fd;
    }
    
    /* ==================== COMPARISON GRID ==================== */
    .comparison-container {
        display: grid;
        grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
        gap: 20px;
        margin: 25px 0;
    }
    
    .comparison-box {
        padding: 25px;
        border-radius: 15px;
        text-align: center;
        box-shadow: 0 5px 15px rgba(0,0,0,0.1);
        transition: transform 0.3s ease;
    }
    
    .comparison-box:hover {
        transform: translateY(-5px);
    }
    
    .comparison-box.blue {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
    }
    
    .comparison-box.green {
        background: linear-gradient(135deg, #11998e 0%, #38ef7d 100%);
        color: white;
    }
    
    .comparison-box .icon {
        font-size: 3em;
        margin-bottom: 15px;
    }
    
    /* ==================== ANIMATED PROCESS FLOW ==================== */
    .process-flow {
        display: flex;
        justify-content: space-around;
        align-items: center;
        margin: 30px 0;
        flex-wrap: wrap;
        position: relative;
    }
    
    .flow-step {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 20px;
        border-radius: 50%;
        width: 150px;
        height: 150px;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        text-align: center;
        font-weight: bold;
        box-shadow: 0 10px 25px rgba(102, 126, 234, 0.3);
        animation: pulse 2s infinite;
        position: relative;
        margin: 10px;
    }
    
    .flow-step .step-number {
        font-size: 2em;
        margin-bottom: 5px;
    }
    
    .flow-step .step-label {
        font-size: 0.9em;
    }
    
    @keyframes pulse {
        0%, 100% {
            transform: scale(1);
            box-shadow: 0 10px 25px rgba(102, 126, 234, 0.3);
        }
        50% {
            transform: scale(1.05);
            box-shadow: 0 15px 35px rgba(102, 126, 234, 0.5);
        }
    }
    
    .flow-step:nth-child(2) {
        animation-delay: 0.5s;
    }
    
    .flow-step:nth-child(3) {
        animation-delay: 1s;
    }
    
    .flow-step:nth-child(4) {
        animation-delay: 1.5s;
    }
    
    .flow-arrow {
        font-size: 2.5em;
        color: #667eea;
        animation: arrowMove 1.5s infinite;
    }
    
    @keyframes arrowMove {
        0%, 100% { transform: translateX(0); }
        50% { transform: translateX(10px); }
    }
    
    /* ==================== REQUIREMENTS SPIRAL DIAGRAM ==================== */
    .spiral-container {
        display: flex;
        justify-content: center;
        align-items: center;
        min-height: 500px;
        position: relative;
        margin: 40px 0;
    }
    
    .spiral-step {
        position: absolute;
        background: white;
        border: 3px solid #667eea;
        border-radius: 15px;
        padding: 20px;
        box-shadow: 0 5px 15px rgba(0,0,0,0.2);
        transition: all 0.3s ease;
        cursor: pointer;
    }
    
    .spiral-step:hover {
        transform: scale(1.1);
        z-index: 10;
        box-shadow: 0 10px 30px rgba(102, 126, 234, 0.4);
    }
    
    .spiral-step h4 {
        color: #667eea;
        margin-bottom: 10px;
    }
    
    /* ==================== INTERACTIVE EXAMPLES ==================== */
    .example-container {
        background: #f8f9fa;
        border-radius: 15px;
        padding: 25px;
        margin: 25px 0;
        border: 2px dashed #667eea;
    }
    
    .example-title {
        color: #667eea;
        font-weight: bold;
        font-size: 1.2em;
        margin-bottom: 15px;
        display: flex;
        align-items: center;
        gap: 10px;
    }
    
    .requirement-item {
        background: white;
        padding: 15px;
        margin: 10px 0;
        border-radius: 10px;
        border-left: 4px solid #667eea;
        transition: all 0.3s ease;
    }
    
    .requirement-item:hover {
        transform: translateX(10px);
        box-shadow: 0 5px 15px rgba(0,0,0,0.1);
    }
    
    /* ==================== METRICS TABLE ==================== */
    .metrics-table {
        width: 100%;
        border-collapse: collapse;
        margin: 25px 0;
        box-shadow: 0 5px 15px rgba(0,0,0,0.1);
        border-radius: 10px;
        overflow: hidden;
    }
    
    .metrics-table thead {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
    }
    
    .metrics-table th,
    .metrics-table td {
        padding: 15px;
        text-align: left;
    }
    
    .metrics-table tbody tr {
        border-bottom: 1px solid #e9ecef;
        transition: background 0.3s ease;
    }
    
    .metrics-table tbody tr:hover {
        background: rgba(102, 126, 234, 0.1);
    }
    
    /* ==================== PROS/CONS LISTS ==================== */
    .pros-cons-container {
        display: grid;
        grid-template-columns: 1fr 1fr;
        gap: 20px;
        margin: 25px 0;
    }
    
    .pros-box, .cons-box {
        padding: 20px;
        border-radius: 15px;
        box-shadow: 0 5px 15px rgba(0,0,0,0.1);
    }
    
    .pros-box {
        background: linear-gradient(135deg, #11998e 0%, #38ef7d 100%);
        color: white;
    }
    
    .cons-box {
        background: linear-gradient(135deg, #eb3349 0%, #f45c43 100%);
        color: white;
    }
    
    .pros-box h3, .cons-box h3 {
        color: white;
        margin-bottom: 15px;
    }
    
    .pros-box ul, .cons-box ul {
        list-style: none;
        padding: 0;
    }
    
    .pros-box li, .cons-box li {
        padding: 8px 0;
        padding-left: 25px;
        position: relative;
    }
    
    .pros-box li::before {
        content: "‚úì";
        position: absolute;
        left: 0;
        font-weight: bold;
        font-size: 1.2em;
    }
    
    .cons-box li::before {
        content: "‚úó";
        position: absolute;
        left: 0;
        font-weight: bold;
        font-size: 1.2em;
    }
    
    /* ==================== QUIZ STYLES ==================== */
    .quiz-container {
        margin: 20px 0;
    }
    
    .question-card {
        background: white;
        border-radius: 15px;
        padding: 25px;
        margin: 20px 0;
        box-shadow: 0 5px 15px rgba(0,0,0,0.1);
        border-left: 5px solid #667eea;
    }
    
    .question-text {
        font-size: 1.1em;
        font-weight: 600;
        margin-bottom: 20px;
        color: #333;
    }
    
    .options-grid {
        display: grid;
        gap: 10px;
    }
    
    .option-btn {
        padding: 15px 20px;
        border: 2px solid #e9ecef;
        background: white;
        border-radius: 10px;
        cursor: pointer;
        transition: all 0.3s ease;
        text-align: left;
        font-size: 1em;
    }
    
    .option-btn:hover {
        border-color: #667eea;
        background: rgba(102, 126, 234, 0.1);
        transform: translateX(5px);
    }
    
    .option-btn.selected {
        background: #667eea;
        color: white;
        border-color: #667eea;
    }
    
    .option-btn.correct {
        background: #28a745;
        color: white;
        border-color: #28a745;
    }
    
    .option-btn.incorrect {
        background: #dc3545;
        color: white;
        border-color: #dc3545;
    }
    
    .check-btn {
        margin-top: 15px;
        padding: 12px 30px;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border: none;
        border-radius: 25px;
        cursor: pointer;
        font-weight: 600;
        transition: all 0.3s ease;
    }
    
    .check-btn:hover {
        transform: translateY(-2px);
        box-shadow: 0 5px 15px rgba(102, 126, 234, 0.4);
    }
    
    .feedback {
        margin-top: 15px;
        padding: 15px;
        border-radius: 10px;
        font-weight: 600;
        animation: slideIn 0.3s ease;
    }
    
    @keyframes slideIn {
        from {
            opacity: 0;
            transform: translateY(-10px);
        }
        to {
            opacity: 1;
            transform: translateY(0);
        }
    }
    
    .feedback.correct {
        background: #d4edda;
        color: #155724;
        border: 2px solid #28a745;
    }
    
    .feedback.incorrect {
        background: #f8d7da;
        color: #721c24;
        border: 2px solid #dc3545;
    }
    
    /* ==================== TOOLTIPS ==================== */
    .tooltip {
        position: relative;
        display: inline-block;
        cursor: help;
        border-bottom: 2px dotted #667eea;
        color: #667eea;
        font-weight: 600;
    }
    
    .tooltip .tooltiptext {
        visibility: hidden;
        width: 300px;
        background-color: #555;
        color: #fff;
        text-align: center;
        border-radius: 6px;
        padding: 10px;
        position: absolute;
        z-index: 1;
        bottom: 125%;
        left: 50%;
        margin-left: -150px;
        opacity: 0;
        transition: opacity 0.3s;
        font-size: 0.9em;
        font-weight: normal;
    }
    
    .tooltip:hover .tooltiptext {
        visibility: visible;
        opacity: 1;
    }
    
    /* ==================== INTERACTIVE BUTTONS ==================== */
    .action-buttons {
        display: flex;
        gap: 15px;
        margin: 20px 0;
        flex-wrap: wrap;
    }
    
    .action-btn {
        padding: 12px 25px;
        border-radius: 25px;
        border: none;
        cursor: pointer;
        font-weight: 600;
        transition: all 0.3s ease;
    }
    
    .action-btn.primary {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
    }
    
    .action-btn.secondary {
        background: white;
        color: #667eea;
        border: 2px solid #667eea;
    }
    
    .action-btn:hover {
        transform: translateY(-2px);
        box-shadow: 0 5px 15px rgba(0,0,0,0.2);
    }
    
    /* ==================== RESPONSIVE DESIGN ==================== */
    @media (max-width: 768px) {
        .header h1 {
            font-size: 1.8em;
        }
        
        .stats-bar {
            flex-wrap: wrap;
        }
        
        .comparison-container,
        .pros-cons-container {
            grid-template-columns: 1fr;
        }
        
        .process-flow {
            flex-direction: column;
        }
        
        .flow-arrow {
            transform: rotate(90deg);
            margin: 10px 0;
        }
        
        .spiral-container {
            min-height: 800px;
        }
    }
    
    /* ==================== LOADING ANIMATION ==================== */
    .loading {
        display: inline-block;
        width: 20px;
        height: 20px;
        border: 3px solid rgba(102, 126, 234, 0.3);
        border-radius: 50%;
        border-top-color: #667eea;
        animation: spin 1s ease-in-out infinite;
    }
    
    @keyframes spin {
        to { transform: rotate(360deg); }
    }
</style>
</head>
<body>
<div class="container">
    <!-- ==================== HEADER ==================== -->
    <div class="header">
        <h1>üß† Week 1: Language Modeling & Transformers</h1>
        <p class="subtitle">From N-grams to BERT, GPT, and ASR</p>
        <div class="progress-container">
            <div class="progress-bar" id="progressBar">0% Complete</div>
        </div>
    </div>
    
    <!-- ==================== GAMIFICATION STATS ==================== -->
    <div class="stats-bar">
        <div class="stat-item">
            <div class="stat-icon">üèÜ</div>
            <div class="stat-label">Points</div>
            <div class="stat-value" id="points">0</div>
        </div>
        <div class="stat-item">
            <div class="stat-icon">‚úÖ</div>
            <div class="stat-label">Completed</div>
            <div class="stat-value" id="completed">0/9</div>
        </div>
        <div class="stat-item">
            <div class="stat-icon">üéØ</div>
            <div class="stat-label">Accuracy</div>
            <div class="stat-value" id="accuracy">0%</div>
        </div>
        <div class="stat-item">
            <div class="stat-icon">‚≠ê</div>
            <div class="stat-label">Streak</div>
            <div class="stat-value" id="streak">0</div>
        </div>
    </div>
    
    <!-- ==================== NAVIGATION TABS ==================== -->
    <div class="nav-tabs">
        <button class="tab-btn active" data-tab="intro-lm">üìö Intro to LMs</button>
        <button class="tab-btn" data-tab="traditional-lm">üìú Traditional LMs</button>
        <button class="tab-btn" data-tab="rnn">üîÑ RNNs</button>
        <button class="tab-btn" data-tab="transformers">ü§ñ Transformers</button>
        <button class="tab-btn" data-tab="pretraining">üèãÔ∏è Pre-training & Fine-tuning</button>
        <button class="tab-btn" data-tab="asr">üó£Ô∏è Speech Recognition</button>
        <button class="tab-btn" data-tab="glossary">üìñ Glossary</button>
        <button class="tab-btn" data-tab="quiz-fill">üìù Fill in the Blank</button>
        <button class="tab-btn" data-tab="quiz-tf">‚ùì True/False</button>
        <button class="tab-btn" data-tab="quiz-mc">üé≤ Multiple Choice</button>
    </div>
    
    <!-- ==================== SECTION 1: Intro to LMs ==================== -->
    <div class="content-section active" data-section="intro-lm">
        <h2>üìö Introduction to Language Models (LMs)</h2>
        
        <div class="info-card">
            <h3>What is Language Modeling?</h3>
            <p><strong>Language Modeling (LM)</strong> is the process of training machines to understand human language in various forms, including text and speech. They learn from large datasets (like books and articles) to recognize common language structures and sequences.</p>
            <p style="margin-top: 10px;"><strong>Think of it like this:</strong> An LM learns to predict the next word in a sentence, or fill in a blank.</p>
            <div class="example-container" style="border-color: #667eea;">
                <div class="example-title">
                    <span>üí°</span>
                    <span>Fill-in-the-Blank Examples:</span>
                </div>
                <div class="requirement-item">
                    Riyadh is the [MASK] of Saudi Arabia ‚Üí <strong>capital</strong>
                </div>
                 <div class="requirement-item">
                    ÿßŸÑÿ≥ŸÑÿßŸÖ ÿπŸÑŸäŸÉŸÖ Ÿàÿ±ÿ≠ŸÖÿ© ÿßŸÑŸÑŸá [MASK] ‚Üí <strong>Ÿàÿ®ÿ±ŸÉÿßÿ™Ÿá</strong>
                </div>
            </div>
        </div>
        
        <div class="info-card success">
            <h3>The Objective of an LM</h3>
            <p>Over time, the model becomes capable of:</p>
            <ul>
                <li>Predicting the most likely next words in a sentence.</li>
                <li>Filling in masked words.</li>
                <li>Correcting misspelled words.</li>
                <li>Providing contextual meanings for words or sentences (as a vector).</li>
            </ul>
        </div>

        <div class="info-card info">
            <h3>Why Do We Need LMs? (Applications)</h3>
            <p>Language models can be used for many applications:</p>
            <ul>
                <li><strong>Text generation:</strong> Writing articles, stories, or even computer code.</li>
                <li><strong>Machine translation:</strong> Creating natural and fluent translations.</li>
                <li><strong>Autocomplete and spelling correction.</strong></li>
                <li><strong>Question answering:</strong> Understanding and responding to questions.</li>
                <li><strong>Dialogue systems:</strong> Powering conversational AI systems.</li>
            </ul>
        </div>
        
        <div class="action-buttons">
            <button class="action-btn primary" onclick="markSectionComplete('intro-lm')">‚úì Mark as Complete</button>
            <button class="action-btn secondary" onclick="navigateToTab('traditional-lm')">Next: Traditional LMs ‚Üí</button>
        </div>
    </div>
    
    <!-- ==================== SECTION 2: Traditional LMs ==================== -->
    <div class="content-section" data-section="traditional-lm">
        <h2>üìú Traditional Language Modeling (N-grams)</h2>
        
        <div class="info-card">
            <h3>The Core Idea</h3>
            <p>Traditional language models define <strong>probability distributions</strong> over sentences. We can use them to score or rank possible sentences. For example, if $P_{LM}(A) > P_{LM}(B)$, it means sentence A is more probable (and likely more correct) than sentence B.</p>
        </div>

        <h3>üé≤ A Quick Probability Review</h3>
        <div class="info-card info">
            <h4>Joint & Conditional Probability</h4>
            <p>The probability of X *given* Y has happened is $P(X|Y) = P(X,Y) / P(Y)$.</p>
            <p>This can be rewritten as: $P(X,Y) = P(X|Y) * P(Y)$.</p>

            <h4>The Chain Rule</h4>
            <p>We can extend this to a full sentence (a sequence of words $X_1, X_2, ..., X_n$):</p>
            <p>$P(X_1, ..., X_n) = P(X_1) * P(X_2|X_1) * P(X_3|X_2, X_1) * ... * P(X_n|X_1, ..., X_{n-1})$</p>
            <p>In plain English: The probability of a whole sentence is the probability of the first word, times the probability of the second word given the first, times the probability of the third word given the first two, and so on.</p>
        </div>

        <div class="info-card warning">
            <h3>The Problem with the Chain Rule</h3>
            <p>Calculating $P(word | all\_previous\_words)$ is too complex and requires too much data! For example, $P(\text{dog} | \text{the quick brown fox jumps over the lazy})$ is impossible to calculate reliably.</p>
        </div>

        <div class="info-card success">
            <h3>The Solution: N-gram Models</h3>
            <p>An <strong>N-gram model</strong> makes a simplifying assumption (called a Markov assumption): a word's probability only depends on the last <strong>n-1</strong> words, not all preceding words.</p>
            
            <h4 style="margin-top: 15px;">Types of N-grams:</h4>
            <ul>
                <li><strong>Unigram (n=1):</strong> "Bag of words." Assumes each word is independent. $P(\text{fox})$</li>
                <li><strong>Bigram (n=2):</strong> Depends on the last 1 word. $P(\text{fox} | \text{brown})$</li>
                <li><strong>Trigram (n=3):</strong> Depends on the last 2 words. $P(\text{fox} | \text{quick brown})$</li>
            </ul>

            <h4 style="margin-top: 15px;">How to Estimate Probabilities (MLE)</h4>
            <p>We use <strong>Maximum Likelihood Estimation (MLE)</strong>, which is just a fancy way of saying "count and divide."</p>
            <p>For a bigram model $P(W_i | W_{i-1})$:</p>
            <p>$P(\text{fox} | \text{brown}) = \frac{\text{Count}(\text{brown fox})}{\text{Count}(\text{brown})}$</p>
            <p>This is called a <strong>relative frequency estimate</strong>.</p>
        </div>

        <h3>üìä How to Evaluate LMs?</h3>
        <div class="comparison-container">
            <div class="comparison-box blue">
                <div class="icon">üî¨</div>
                <h3>Intrinsic Evaluation</h3>
                <p>Assesses how well the model captures what it was designed to capture (like probabilities). Uses metrics like <strong>Perplexity</strong>.</p>
            </div>
            <div class="comparison-box green">
                <div class="icon">üöÄ</div>
                <h3>Extrinsic (Task-based) Evaluation</h3>
                <p>Measures how useful the model is for a particular task (like translation or speech recognition). Uses metrics like <strong>WER</strong> or <strong>BLEU</strong>.</p>
            </div>
        </div>

        <div class="info-card">
            <h3>What is Perplexity?</h3>
            <p><strong>Perplexity (PP)</strong> is the most common intrinsic metric. It's the inverse probability of the test set, normalized by the number of words.</p>
            <p><strong>In simple terms:</strong> A lower perplexity score means the language model is better at predicting the next word. It is "less surprised" by the test data.</p>
            <p>$Perplexity = \exp\left(-\frac{1}{N} \sum_{i} \log(P(W_i | W_1, ..., W_{i-1}))\right)$</p>
        </div>

        <div class="action-buttons">
            <button class="action-btn primary" onclick="markSectionComplete('traditional-lm')">‚úì Mark as Complete</button>
            <button class="action-btn secondary" onclick="navigateToTab('rnn')">Next: RNNs ‚Üí</button>
        </div>
    </div>
    
    <!-- ==================== SECTION 3: RNNs ==================== -->
    <div class="content-section" data-section="rnn">
        <h2>üîÑ Recurrent Neural Networks (RNNs)</h2>
        
        <div class="info-card">
            <h3>What is an RNN?</h3>
            <p>A <strong>Recurrent Neural Network (RNN)</strong> is a specialized type of neural network designed to handle <strong>sequential data</strong> or time series data. Unlike traditional Feed-forward Neural Networks (FNNs), RNNs can capture and learn from patterns and dependencies within sequential information.</p>
        </div>

        <h3>FNN vs. RNN: The Big Difference</h3>
        <div class="comparison-container">
            <div class="comparison-box" style="background: linear-gradient(135deg, #a8edea 0%, #fed6e3 100%); color: #333;">
                <div class="icon">‚û°Ô∏è</div>
                <h3>Feed-forward NN (FNN)</h3>
                <p>Input $X$ goes in, Output $Y$ comes out. There is no concept of time or memory of past inputs.</p>
                <p>$h = F_1(W_x \cdot X + b_x)$</p>
                <p>$y = F_2(W_y \cdot h + b_y)$</p>
            </div>
            <div class="comparison-box" style="background: linear-gradient(135deg, #ffecd2 0%, #fcb69f 100%); color: #333;">
                <div class="icon">üîÑ</div>
                <h3>Recurrent NN (RNN)</h3>
                <p>The output at time $t$ depends on the input $X^t$ AND the "hidden state" $h^{t-1}$ from the previous step. It has a "memory"!</p>
                <p>$h^t = F_1(W_{hh} \cdot h^{t-1} + W_{hx} \cdot X^t + b_h)$</p>
                <p>$y^t = F_2(W_y \cdot h^t + b_y)$</p>
            </div>
        </div>

        <h3>Common RNN Architectures</h3>
        <div class="info-card info">
            <ul>
                <li><strong>One-to-many:</strong> e.g., Image Captioning (Input: 1 image, Output: sequence of words)</li>
                <li><strong>Many-to-one:</strong> e.g., Sentiment Analysis (Input: sequence of words, Output: 1 label)</li>
                <li><strong>Many-to-many:</strong> e.g., Machine Translation (Input: sequence, Output: sequence)</li>
            </ul>
        </div>

        <div class="info-card danger">
            <h3>Limitations of Vanilla RNNs</h3>
            <ol>
                <li><strong>Vanishing/Exploding Gradient Problem:</strong> During training (Backpropagation Through Time), gradients can become exponentially small (vanish) or large (explode), making it very hard to learn long-term dependencies.</li>
                <li><strong>Limited Memory Capacity:</strong> The RNN's "memory" $h^t$ struggles to remember information from many steps ago.</li>
                <li><strong>Difficulty in Parallel Processing:</strong> The sequential nature (needing $h^{t-1}$ to calculate $h^t$) makes it slow.</li>
            </ol>
        </div>

        <div class="info-card success">
            <h3>Solution: LSTM (Long Short-Term Memory)</h3>
            <p>LSTMs are a special type of RNN that are much better at learning long-term dependencies. They do this by introducing a <strong>"cell state" ($C^t$)</strong> and three "gates":</p>
            <ul>
                <li><strong>Forget Gate ($f^t$):</strong> Decides what information to throw away from the cell state.</li>
                <li><strong>Input Gate ($i^t$):</strong> Decides what new information to store in the cell state.</li>
                <li><strong>Output Gate ($o^t$):</strong> Decides what to output based on the cell state.</li>
            </ul>
            <p>This gating mechanism allows the network to selectively remember or forget information over long periods.</p>
        </div>

        <h3>From RNNs to Sequence-to-Sequence (seq2seq)</h3>
        <div class="info-card">
            <h4>Seq2Seq Model</h4>
            <p>Used for tasks like translation, this model has two parts:</p>
            <ol>
                <li><strong>Encoder:</strong> An RNN (or LSTM) that reads the input sequence (e.g., "Hello") and compresses it into a single "context vector" ($C$).</li>
                <li><strong>Decoder:</strong> Another RNN that takes the context vector $C$ and generates the output sequence (e.g., "Bonjour").</li>
            </ol>
            <h4 class="danger" style="color: #dc3545;">Problem: The single context vector $C$ is a bottleneck! It's hard to cram the meaning of a long sentence into one vector.</h4>
        </div>

        <div class="info-card success">
            <h3>The Breakthrough: Seq2Seq with Attention</h3>
            <p>Instead of one fixed context vector, the <strong>Attention</strong> mechanism allows the decoder to "look back" at *all* the encoder's hidden states at *every* step of its output.</p>
            <p>It learns to "pay attention" to the most relevant input words when generating the current output word.</p>
            <p>This solves the bottleneck problem and dramatically improves performance, especially for long sequences.</p>
            <h4 class="info" style="color: #17a2b8;">This "attention" concept is the key idea that leads directly to Transformers!</h4>
        </div>

        <div class="action-buttons">
            <button class="action-btn primary" onclick="markSectionComplete('rnn')">‚úì Mark as Complete</button>
            <button class="action-btn secondary" onclick="navigateToTab('transformers')">Next: Transformers ‚Üí</button>
        </div>
    </div>
    
    <!-- ==================== SECTION 4: Transformers ==================== -->
    <div class="content-section" data-section="transformers">
        <h2>ü§ñ Introduction to Transformers</h2>
        
        <div class="info-card">
            <h3>The Problem with RNNs/LSTMs</h3>
            <p>Even with Attention, LSTMs are still <strong>sequential</strong>. They must process words one by one, which is slow and makes parallel processing difficult.</p>
            <p><strong>The Big Question:</strong> Can we build a model that uses attention but isn't sequential?</p>
            <h3>Yes! The Transformer (Paper: "Attention Is All You Need")</h3>
        </div>

        <div class="info-card success">
            <h3>The Core Idea: Self-Attention</h3>
            <p>Instead of an RNN, the Transformer uses a new mechanism called <strong>Self-Attention</strong>. This layer allows every word in a sentence to look at and score its relationship with *every other word* in the *same sentence*, all at once (in parallel).</p>
            
            <h4>How it Works (Simplified):</h4>
            <p>For each input word vector $x_i$, the model learns three new vectors:</p>
            <ul>
                <li><strong>Query ($q_i$):</strong> "What am I looking for?"</li>
                <li><strong>Key ($k_i$):</strong> "What information do I have?"</li>
                <li><strong>Value ($v_i$):</strong> "What is the actual content I'll share?"</li>
            </ul>
            <p>The output $y_j$ for a word is a weighted sum of all other words' Value vectors ($v_i$). The weight (attention score) is calculated based on how well the Query $q_j$ matches the Key $k_i$.</p>
            <p><strong>This mechanism directly computes the "contextual meaning" of a word based on its entire surroundings.</strong></p>
        </div>

        <div class="info-card danger">
            <h3>A New Problem: Position</h3>
            <p>If you just use self-attention, the model has no idea what order the words are in! "The dog bit the man" and "The man bit the dog" would look the same.</p>
            <h4>Solution: Positional Encoding</h4>
            <p>Before feeding the words into the model, we add a "position vector" (Positional Encoding) to each word's embedding. This vector gives the model a unique signal about the word's position in the sequence (e.g., 1st, 2nd, 3rd...).</p>
        </div>

        <h3>The Transformer Architecture</h3>
        <div class="info-card info">
            <p>The original Transformer has two main parts, just like seq2seq:</p>
            <ol>
                <li><strong>The Encoder (Left Side):</strong>
                    <ul>
                        <li>Reads the input sentence (e.g., in German).</li>
                        <li>Uses <strong>Self-Attention</strong> layers (where words look at other words in the same sentence).</li>
                        <li>Passes through a Feed Forward network.</li>
                        <li>This is stacked $N$ times.</li>
                        <li>Output: A set of contextualized vectors, one for each input word.</li>
                    </ul>
                </li>
                <li><strong>The Decoder (Right Side):</strong>
                    <ul>
                        <li>Generates the output sentence (e.g., in English).</li>
                        <li>Uses <strong>Masked Self-Attention</strong> (words can only look at *previous* words in the generated sentence, so they can't "cheat").</li>
                        <li>Uses <strong>Cross-Attention</strong> (where the decoder "looks at" the Encoder's output, just like in seq2seq with attention).</li>
                        <li>Passes through a Feed Forward network.</li>
                        <li>This is also stacked $N$ times.</li>
                    </ul>
                </li>
            </ol>
        </div>

        <div class="comparison-container">
            <div class="comparison-box blue">
                <div class="icon">ü§ñ</div>
                <h3>Transformers</h3>
                <p>Good at long sequences (attention looks at all inputs).</p>
                <p>Can be highly parallel (no sequential RNNs).</p>
                <p>Needs Positional Encodings to understand order.</p>
            </div>
            <div class="comparison-box green">
                <div class="icon">üîÑ</div>
                <h3>RNNs (LSTMs)</h3>
                <p>Works reasonably well for long sequences (with attention).</p>
                <p>Strictly sequential computation (slow).</p>
                <p>Inherently understands order (processes 1st, then 2nd...)</p>
            </div>
        </div>

        <div class="action-buttons">
            <button class="action-btn primary" onclick="markSectionComplete('transformers')">‚úì Mark as Complete</button>
            <button class="action-btn secondary" onclick="navigateToTab('pretraining')">Next: Pre-training ‚Üí</button>
        </div>
    </div>
    
    <!-- ==================== SECTION 5: Pre-training ==================== -->
    <div class="content-section" data-section="pretraining">
        <h2>üèãÔ∏è Pre-training & Fine-tuning</h2>
        
        <div class="info-card">
            <h3>The Two-Step Process</h3>
            <p>Transformers are powerful but need a *ton* of data. The solution is a two-step process:</p>
            <ol>
                <li><strong>Pre-training (Unsupervised):</strong> Train the Transformer on a *massive*, general-purpose dataset (like the entire internet). The model isn't trained for any specific task, just to understand language. This creates "contextualized embeddings."</li>
                <li><strong>Fine-tuning (Supervised):</strong> Take the powerful pre-trained model and train it *a little more* on a *small*, specialized dataset for your specific task (like translation or question-answering).</li>
            </ol>
            <p>This fine-tuning only requires a small amount of data because the model *already* has a strong foundation of language from pre-training.</p>
        </div>

        <h3>Model Spotlight: BERT (Encoder-Only)</h3>
        <div class="info-card info">
            <h4>BERT = Bidirectional Encoder Representations from Transformers</h4>
            <p>BERT uses <strong>only the Encoder part</strong> of the Transformer. It's pre-trained on two "unsupervised" tasks:</p>
            <ol>
                <li><strong>Masked Language Model (MLM):</strong>
                    <ul>
                        <li>Takes a sentence and masks 15% of the words. (e.g., "The quick brown [MASK] jumps over the [MASK] dog.")</li>
                        <li>The model's job is to predict the *original* masked words.</li>
                        <li>This forces it to learn context from *both* the left and the right (it's bidirectional).</li>
                    </ul>
                </li>
                <li><strong>Next Sentence Prediction (NSP):</strong>
                    <ul>
                        <li>The model is given two sentences, A and B.</li>
                        <li>It must predict if sentence B is the *actual* next sentence that followed A in the text, or if it's just a random sentence from the corpus.</li>
                        <li>This teaches the model about sentence relationships.</li>
                    </ul>
                </li>
            </ol>
            <h4>Fine-tuning BERT:</h4>
            <p>To fine-tune BERT for a task like sentiment analysis, you add a small "Classifier Head" (a linear layer) on top. You then train this small head (and slightly adjust the BERT model) on your sentiment dataset.</p>
        </div>

        <h3>Model Spotlight: GPT (Decoder-Only)</h3>
        <div class="info-card success">
            <h4>GPT = Generative Pre-trained Transformer</h4>
            <p>GPT uses <strong>only the Decoder part</strong> of the Transformer. It's pre-trained on one simple task:</p>
            <ol>
                <li><strong>Next Token Prediction (Causal LM):</strong>
                    <ul>
                        <li>Given a sentence, the model's job is to predict the *very next word*. (e.g., "The quick brown fox jumps over the lazy [?]")</li>
                        <li>Because it's a Decoder, it uses <strong>Masked Self-Attention</strong>, so it can only look at *past* words. This is "unidirectional" or "causal."</li>
                    </ul>
                </li>
            </ol>
            <h4>Fine-tuning/Using GPT:</h4>
            <p>GPT is naturally good at *generating* new text. You give it a "prompt" (a starting sequence), and it will just keep predicting the next word, and the next, and the next... This is used for chatbots, text completion, code generation, summarization, and more.</p>
        </div>

        <div class="action-buttons">
            <button class="action-btn primary" onclick="markSectionComplete('pretraining')">‚úì Mark as Complete</button>
            <button class="action-btn secondary" onclick="navigateToTab('asr')">Next: Speech Recognition ‚Üí</button>
        </div>
    </div>
    
    <!-- ==================== SECTION 6: ASR ==================== -->
    <div class="content-section" data-section="asr">
        <h2>üó£Ô∏è Speech Recognition (ASR)</h2>
        
        <div class="info-card">
            <h3>What is Speech Recognition?</h3>
            <p><strong>Speech Recognition (ASR)</strong> is a technology that enables computers to identify and process spoken language, converting audio input into text. It's used in virtual assistants, transcription services, and voice-activated systems.</p>
        </div>

        <h3>How ASR Works: The Feature Pipeline</h3>
        <div class="info-card info">
            <p>Raw audio waveforms (just a series of numbers) are not very useful. We must first extract meaningful features. The most common feature is the <strong>MFCC (Mel-Frequency Cepstral Coefficients)</strong>.</p>
            
            <h4>The MFCC Pipeline:</h4>
            <ol>
                <li><strong>Pre-emphasis:</strong> Boost high-frequency energy.</li>
                <li><strong>Framing:</strong> Divide the signal into short, overlapping frames (e.g., 25ms).</li>
                <li><strong>Windowing:</strong> Apply a window function (like Hamming) to each frame.</li>
                <li><strong>FFT:</strong> Convert each frame from the time domain to the frequency domain.</li>
                <li><strong>Mel Filterbank:</strong> Apply filters spaced on the "Mel scale" (which mimics human hearing). This creates a <strong>Spectrogram</strong>.</li>
                <li><strong>Logarithm:</strong> Take the log of the filterbank energies (mimics human perception of loudness).</li>
                <li><strong>DCT (Discrete Cosine Transform):</strong> "Compress" the filterbank energies to get a small set of coefficients (the MFCCs).</li>
            </ol>
            <p>The output is a sequence of vectors (one for each frame), which can be fed into a model like an RNN or Transformer!</p>
        </div>

        <h3>Traditional ASR vs. End-to-End (E2E)</h3>
        <div class="comparison-container">
            <div class="comparison-box blue">
                <div class="icon">üèõÔ∏è</div>
                <h3>Traditional ASR</h3>
                <p>Uses separate, complex components:</p>
                <ul>
                    <li><strong>Acoustic Model (HMM-GMM):</strong> Maps audio features to phonemes (sounds).</li>
                    <li><strong>Pronunciation Model:</strong> Maps phonemes to words.</li>
                    <li><strong>Language Model:</strong> Scores which sequence of words is most likely (e.g., "eat apples" > "eatin aples").</li>
                </ul>
            </div>
            <div class="comparison-box green">
                <div class="icon">üöÄ</div>
                <h3>End-to-End (E2E) ASR</h3>
                <p>Uses a single, deep neural network (like an RNN or Transformer) to map *directly* from audio features (like MFCCs) to text.</p>
                <p>Much simpler to train and often more accurate.</p>
            </div>
        </div>

        <div class="info-card">
            <h3>Key E2E ASR Concepts & Models</h3>
            
            <h4>Connectionist Temporal Classification (CTC)</h4>
            <p>A "loss function" (a way to train the model) used in ASR. It's brilliant because it solves the "alignment" problem. It doesn't need to know *exactly* which audio frame corresponds to which letter.</p>
            <p>It adds a special <strong>"blank" token (‚Ç¨)</strong> and collapses repeated/blank tokens. For example, the model output "h-e-e-‚Ç¨-l-l-‚Ç¨-o-o-!" just gets collapsed down to <strong>"hello!"</strong>.</p>

            <h4>Modern ASR Models:</h4>
            <ul>
                <li><strong>DeepSpeech:</strong> Based on RNNs and CTC loss.</li>
                <li><strong>Jasper / QuartzNet:</strong> Uses 1D Convolutional layers with CTC loss.</li>
                <li><strong>Conformer:</strong> A modern architecture that combines the best of CNNs and Transformers to capture both local and global audio dependencies.</li>
                <li><strong>Wav2Vec 2.0 (Self-Supervised):</strong> A breakthrough model. It's pre-trained *directly on raw audio* (no transcripts!) using a "contrastive loss" (similar to BERT's MLM). It's then fine-tuned on a small amount of labeled data.</li>
                <li><strong>Whisper:</strong> A large-scale model from OpenAI trained on 680,000 hours of multilingual, multitask data. It's an Encoder-Decoder Transformer that can perform transcription, translation, and language identification all at once.</li>
            </ul>
        </div>
        
        <div class="action-buttons">
            <button class="action-btn primary" onclick="markSectionComplete('asr')">‚úì Mark as Complete</button>
            <button class="action-btn secondary" onclick="navigateToTab('glossary')">Next: Glossary ‚Üí</button>
        </div>
    </div>

    <!-- ==================== SECTION 7: GLOSSARY ==================== -->
    <div class="content-section" data-section="glossary">
        <h2>üìñ Week 1 Glossary</h2>
        <p>Click on any term to expand its definition and learn more!</p>
        
        <div class="glossary-accordion">
            <div class="accordion-item">
                <div class="accordion-header">
                    <span>Language Model (LM)</span>
                    <span class="icon">‚ñº</span>
                </div>
                <div class="accordion-content">
                    <p>A model that defines a probability distribution over sequences of words. It's trained to understand human language and can be used for tasks like text generation, translation, and autocomplete.</p>
                </div>
            </div>
            
            <div class="accordion-item">
                <div class="accordion-header">
                    <span>N-gram Model</span>
                    <span class="icon">‚ñº</span>
                </div>
                <div class="accordion-content">
                    <p>A traditional language model that assumes the probability of a word depends only on the previous $n-1$ words. (e.g., Bigram $n=2$, Trigram $n=3$).</p>
                </div>
            </div>

            <div class="accordion-item">
                <div class="accordion-header">
                    <span>Perplexity (PP)</span>
                    <span class="icon">‚ñº</span>
                </div>
                <div class="accordion-content">
                    <p>An intrinsic evaluation metric for language models. A lower perplexity score indicates a better model that is "less surprised" by the test data and more accurate at predicting the next word.</p>
                </div>
            </div>

            <div class="accordion-item">
                <div class="accordion-header">
                    <span>Recurrent Neural Network (RNN)</span>
                    <span class="icon">‚ñº</span>
                </div>
                <div class="accordion-content">
                    <p>A type of neural network designed for sequential data. It maintains a "hidden state" (or "memory") that captures information from previous steps in the sequence.</p>
                </div>
            </div>

            <div class="accordion-item">
                <div class="accordion-header">
                    <span>Vanishing/Exploding Gradients</span>
                    <span class="icon">‚ñº</span>
                </div>
                <div class="accordion-content">
                    <p>A problem in training deep networks, especially RNNs. Gradients (error signals) can become exponentially small (vanish) or large (explode) as they are propagated back through time, making it hard to learn long-term dependencies.</p>
                </div>
            </div>

            <div class="accordion-item">
                <div class="accordion-header">
                    <span>LSTM (Long Short-Term Memory)</span>
                    <span class="icon">‚ñº</span>
                </div>
                <div class="accordion-content">
                    <p>A special type of RNN that uses "gates" (Forget, Input, Output) and a "cell state" to effectively learn and remember information over long sequences, solving the vanishing gradient problem.</p>
                </div>
            </div>

            <div class="accordion-item">
                <div class="accordion-header">
                    <span>Seq2Seq (Sequence-to-Sequence)</span>
                    <span class="icon">‚ñº</span>
                </div>
                <div class="accordion-content">
                    <p>An architecture composed of an Encoder (which reads an input sequence into a context vector) and a Decoder (which generates an output sequence from that vector). Used for tasks like machine translation.</p>
                </div>
            </div>

            <div class="accordion-item">
                <div class="accordion-header">
                    <span>Attention Mechanism</span>
                    <span class="icon">‚ñº</span>
                </div>
                <div class="accordion-content">
                    <p>A mechanism, first used with Seq2Seq models, that allows a decoder to look back at all of the encoder's hidden states, weighting them to "pay attention" to the most relevant input words at each step of output generation.</p>
                </div>
            </div>

            <div class="accordion-item">
                <div class="accordion-header">
                    <span>Transformer</span>
                    <span class="icon">‚ñº</span>
                </div>
                <div class="accordion-content">
                    <p>A modern neural network architecture (from "Attention Is All You Need") that relies *entirely* on attention mechanisms (specifically Self-Attention) and avoids sequential RNNs, allowing for massive parallelization and state-of-the-art performance.</p>
                </div>
            </div>

            <div class="accordion-item">
                <div class="accordion-header">
                    <span>Self-Attention</span>
                    <span class="icon">‚ñº</span>
                </div>
                <div class="accordion-content">
                    <p>The core mechanism of the Transformer. It allows every word in a sequence to look at and score its relationship with every *other* word in the *same* sequence, all at once, to build a contextual representation.</p>
                </div>
            </div>

            <div class="accordion-item">
                <div class="accordion-header">
                    <span>Positional Encoding</span>
                    <span class="icon">‚ñº</span>
                </div>
                <div class="accordion-content">
                    <p>A vector added to a word's embedding in a Transformer to give the model information about the word's position (e.g., 1st, 2nd, 3rd) in the sequence, which Self-Attention alone does not capture.</p>
                </div>
            </div>

            <div class="accordion-item">
                <div class="accordion-header">
                    <span>BERT (Bidirectional Encoder...)</span>
                    <span class="icon">‚ñº</span>
                </div>
                <div class="accordion-content">
                    <p>A pre-trained model based on the Transformer <strong>Encoder</strong>. It's "bidirectional" because it's pre-trained using a Masked Language Model (MLM) task, forcing it to learn context from both the left and right of a word.</p>
                </div>
            </div>

            <div class="accordion-item">
                <div class="accordion-header">
                    <span>GPT (Generative Pre-trained...)</span>
                    <span class="icon">‚ñº</span>
                </div>
                <div class="accordion-content">
                    <p>A pre-trained model based on the Transformer <strong>Decoder</strong>. It's "unidirectional" or "causal" because it's pre-trained on a Next Token Prediction task, where it can only look at past words to predict the next one. This makes it excellent for text generation.</p>
                </div>
            </div>

            <div class="accordion-item">
                <div class="accordion-header">
                    <span>ASR (Automatic Speech Recognition)</span>
                    <span class="icon">‚ñº</span>
                </div>
                <div class="accordion-content">
                    <p>A technology that converts spoken audio into written text.</p>
                </div>
            </div>

            <div class="accordion-item">
                <div class="accordion-header">
                    <span>MFCC (Mel-Frequency Cepstral... )</span>
                    <span class="icon">‚ñº</span>
                </div>
                <div class="accordion-content">
                    <p>A standard way to extract features from an audio signal to be fed into a machine learning model. It converts a raw waveform into a sequence of vectors that represent the sound, mimicking human hearing perception.</p>
                </div>
            </div>

            <div class="accordion-item">
                <div class="accordion-header">
                    <span>CTC (Connectionist Temporal...)</span>
                    <span class="icon">‚ñº</span>
                </div>
                <div class="accordion-content">
                    <p>A loss function used to train ASR models. It solves the alignment problem by using a special "blank" token and collapsing repeated/blank characters, allowing the model to map an audio sequence to a shorter text sequence without an explicit alignment.</p>
                </div>
            </div>

        </div>
        
        <div class="action-buttons">
            <button class="action-btn primary" onclick="markSectionComplete('glossary')">‚úì Mark as Complete</button>
            <button class="action-btn secondary" onclick="navigateToTab('quiz-fill')">Ready for Quiz? ‚Üí</button>
        </div>
    </div>
    
    <!-- ==================== QUIZ SECTION: FILL IN THE BLANK ==================== -->
    <div class="content-section" data-section="quiz-fill">
        <h2>üìù Fill in the Blank Quiz</h2>
        <p>Test your knowledge by selecting the correct word to fill in each blank!</p>
        
        <div class="quiz-container" id="fillQuizContainer"></div>
        
        <div class="action-buttons" style="margin-top: 30px;">
            <button class="action-btn primary" onclick="checkAllFillAnswers()">Check All Answers</button>
            <button class="action-btn secondary" onclick="navigateToTab('quiz-tf')">Next: True/False Quiz ‚Üí</button>
        </div>
    </div>
    
    <!-- ==================== QUIZ SECTION: TRUE/FALSE ==================== -->
    <div class="content-section" data-section="quiz-tf">
        <h2>‚ùì True/False Quiz</h2>
        <p>Determine whether each statement is true or false!</p>
        
        <div class="quiz-container" id="tfQuizContainer"></div>
        
        <div class="action-buttons" style="margin-top: 30px;">
            <button class="action-btn primary" onclick="checkAllTFAnswers()">Check All Answers</button>
            <button class="action-btn secondary" onclick="navigateToTab('quiz-mc')">Next: Multiple Choice Quiz ‚Üí</button>
        </div>
    </div>
    
    <!-- ==================== QUIZ SECTION: MULTIPLE CHOICE ==================== -->
    <div class="content-section" data-section="quiz-mc">
        <h2>üé≤ Multiple Choice Quiz</h2>
        <p>Choose the best answer for each question!</p>
        
        <div class="quiz-container" id="mcQuizContainer"></div>
        
        <div class="action-buttons" style="margin-top: 30px;">
            <button class="action-btn primary" onclick="checkAllMCAnswers()">Check All Answers</button>
            <button class="action-btn secondary" onclick="showFinalResults()">View Final Results üèÜ</button>
        </div>
    </div>
</div>

<script>
// ==================== GAMIFICATION DATA ====================
let gameData = {
    points: 0,
    completedSections: new Set(),
    totalSections: 7, // 6 content sections + 1 glossary
    correctAnswers: 0,
    totalAnswers: 0,
    streak: 0,
    sectionCompletion: {}
};

// ==================== QUIZ DATA (All questions based on W1_Transformers... PDF) ====================
const fillInTheBlankQuiz = [
    {
        question: "A _______ model assumes that a word's probability only depends on the last n-1 words.",
        options: ["RNN", "Transformer", "N-gram", "Seq2Seq"],
        answer: "N-gram"
    },
    {
        question: "A lower _______ score indicates a better language model that is 'less surprised' by the test data.",
        options: ["Perplexity", "Accuracy", "BLEU", "CTC"],
        answer: "Perplexity"
    },
    {
        question: "The core problem in training deep RNNs, where gradients become too small or too large, is called the _______ Gradient Problem.",
        options: ["Sequential", "Attention", "Vanishing/Exploding", "Backpropagation"],
        answer: "Vanishing/Exploding"
    },
    {
        question: "A _______ model uses an Encoder to read an input sequence and a Decoder to generate an output sequence.",
        options: ["Seq2Seq", "BERT", "GPT", "Wav2Vec"],
        answer: "Seq2Seq"
    },
    {
        question: "The core mechanism of the Transformer, which allows every word to look at every other word in parallel, is called _______.",
        options: ["Recurrence", "Self-Attention", "CTC Loss", "MFCC"],
        answer: "Self-Attention"
    },
    {
        question: "The pre-training task for BERT, where 15% of words are hidden, is called _______ Language Model (MLM).",
        options: ["Causal", "Masked", "Next-Sentence", "Generative"],
        answer: "Masked"
    },
    {
        question: "The pre-training task for GPT, where the model predicts the next word, is called _______ Language Model (Causal LM).",
        options: ["Next Token Prediction", "Masked", "Bidirectional", "Self-Supervised"],
        answer: "Next Token Prediction"
    },
    {
        question: "The most common feature extracted from audio for ASR, which mimics human hearing, is the _______.",
        options: ["MFCC", "FFT", "Spectrogram", "Raw Waveform"],
        answer: "MFCC"
    },
    {
        question: "The _______ loss function solves the ASR alignment problem by using a special 'blank' token and collapsing repeats.",
        options: ["Cross-Entropy", "Contrastive", "CTC", "Triplet"],
        answer: "CTC"
    },
    {
        question: "_______ is a self-supervised model that is pre-trained directly on raw audio waveforms using a contrastive loss.",
        options: ["Whisper", "BERT", "DeepSpeech", "Wav2Vec 2.0"],
        answer: "Wav2Vec 2.0"
    }
];

const trueFalseQuiz = [
    {
        question: "A Unigram model considers the previous word when calculating probability.",
        answer: false
    },
    {
        question: "Extrinsic evaluation measures how useful a language model is for a specific task, like translation.",
        answer: true
    },
    {
        question: "A vanilla RNN is very good at learning long-term dependencies (e.g., relationships between words far apart).",
        answer: false
    },
    {
        question: "LSTMs use gates (Forget, Input, Output) to control the flow of information and solve the vanishing gradient problem.",
        answer: true
    },
    {
        question: "The 'Attention' mechanism in Seq2Seq models creates a single, fixed-size context vector, which is a bottleneck.",
        answer: false
    },
    {
        question: "The Transformer architecture (from 'Attention Is All You Need') is sequential and cannot be parallelized.",
        answer: false
    },
    {
        question: "Transformers need 'Positional Encodings' because the Self-Attention mechanism itself doesn't know the order of words.",
        answer: true
    },
    {
        question: "BERT is a 'bidirectional' model because it's trained to predict the next token (Causal LM).",
        answer: false
    },
    {
        question: "GPT is a 'causal' or 'unidirectional' model because it's trained to predict the next token.",
        answer: true
    },
    {
        question: "Whisper is a large-scale ASR model that can only perform English transcription.",
        answer: false
    }
];

const multipleChoiceQuiz = [
    {
        question: "Which of these is NOT a key component of an LSTM?",
        options: [
            "Forget Gate",
            "Input Gate",
            "Cell State",
            "Self-Attention"
        ],
        answer: "Self-Attention"
    },
    {
        question: "In a Seq2Seq model, what is the 'bottleneck' problem that 'Attention' solves?",
        options: [
            "The model is too slow to train.",
            "The model can't handle long sequences.",
            "The entire meaning of the input sequence must be compressed into one fixed-size context vector.",
            "The model uses too much memory."
        ],
        answer: "The entire meaning of the input sequence must be compressed into one fixed-size context vector."
    },
    {
        question: "What are the three vectors each word creates in a Self-Attention layer?",
        options: [
            "Input, Output, Hidden",
            "Query, Key, Value",
            "Forget, Input, Output",
            "Encoder, Decoder, Context"
        ],
        answer: "Query, Key, Value"
    },
    {
        question: "Which model architecture is based on the Transformer ENCODER and uses Masked Language Model (MLM) for pre-training?",
        options: [
            "GPT",
            "LSTM",
            "BERT",
            "Wav2Vec 2.0"
        ],
        answer: "BERT"
    },
    {
        question: "Which model architecture is based on the Transformer DECODER and uses Next Token Prediction for pre-training?",
        options: [
            "GPT",
            "BERT",
            "HMM",
            "Conformer"
        ],
        answer: "GPT"
    },
    {
        question: "In ASR, what is the main purpose of extracting MFCCs?",
        options: [
            "To convert text back into speech.",
            "To translate the speech to another language.",
            "To convert the raw audio waveform into a sequence of meaningful feature vectors.",
            "To remove all background noise from the audio."
        ],
        answer: "To convert the raw audio waveform into a sequence of meaningful feature vectors."
    },
    {
        question: "What is the primary function of the CTC Loss function in ASR?",
        options: [
            "To extract MFCC features from audio.",
            "To align the audio sequence with the text sequence using a 'blank' token, removing the need for pre-alignment.",
            "To translate the transcribed text into another language.",
            "To mask 15% of the audio frames for a pre-training task."
        ],
        answer: "To align the audio sequence with the text sequence using a 'blank' token, removing the need for pre-alignment."
    },
    {
        question: "What is a key difference between Transformers and RNNs?",
        options: [
            "RNNs can be parallelized, but Transformers cannot.",
            "Transformers process data sequentially, while RNNs use attention.",
            "Transformers are not good at handling long sequences.",
            "Transformers are highly parallel (using Self-Attention), while RNNs are sequential."
        ],
        answer: "Transformers are highly parallel (using Self-Attention), while RNNs are sequential."
    },
    {
        question: "Which ASR model combines CNNs and Transformers to capture both local and global dependencies in audio?",
        options: [
            "DeepSpeech",
            "HMM-GMM",
            "Conformer",
            "BERT"
        ],
        answer: "Conformer"
    },
    {
        question: "What is the two-step process for using large Transformer models?",
        options: [
            "1. Train on audio, 2. Train on text",
            "1. Pre-training on a massive, general dataset, 2. Fine-tuning on a small, specific dataset",
            "1. Fine-tuning on a small dataset, 2. Pre-training on a massive dataset",
            "1. Use an Encoder, 2. Use a Decoder"
        ],
        answer: "1. Pre-training on a massive, general dataset, 2. Fine-tuning on a small, specific dataset"
    }
];

// ==================== NAVIGATION FUNCTIONS ====================
function navigateToTab(tabName) {
    const tabs = document.querySelectorAll('.tab-btn');
    const sections = document.querySelectorAll('.content-section');
    
    tabs.forEach(tab => {
        if (tab.dataset.tab === tabName) {
            tab.classList.add('active');
        } else {
            tab.classList.remove('active');
        }
    });
    
    sections.forEach(section => {
        if (section.dataset.section === tabName) {
            section.classList.add('active');
        } else {
            section.classList.remove('active');
        }
    });
    
    window.scrollTo({ top: 0, behavior: 'smooth' });
}

// ==================== SECTION COMPLETION ====================
function markSectionComplete(sectionName) {
    if (!gameData.completedSections.has(sectionName)) {
        gameData.completedSections.add(sectionName);
        gameData.points += 10;
        gameData.sectionCompletion[sectionName] = true;
        
        // Add badge to tab
        const tab = document.querySelector(`[data-tab="${sectionName}"]`);
        if (tab && !tab.querySelector('.badge')) {
            const badge = document.createElement('span');
            badge.className = 'badge';
            badge.textContent = '‚úì';
            tab.appendChild(badge);
        }
        
        updateGameStats();
        showCompletionAnimation();
    }
}

function updateGameStats() {
    document.getElementById('points').textContent = gameData.points;
    document.getElementById('completed').textContent = `${gameData.completedSections.size}/${gameData.totalSections}`;
    
    const accuracy = gameData.totalAnswers > 0 
        ? Math.round((gameData.correctAnswers / gameData.totalAnswers) * 100) 
        : 0;
    document.getElementById('accuracy').textContent = `${accuracy}%`;
    document.getElementById('streak').textContent = gameData.streak;
    
    const progress = (gameData.completedSections.size / gameData.totalSections) * 100;
    const progressBar = document.getElementById('progressBar');
    progressBar.style.width = `${progress}%`;
    progressBar.textContent = `${Math.round(progress)}% Complete`;
}

function showCompletionAnimation() {
    // Create celebration animation
    const celebration = document.createElement('div');
    celebration.innerHTML = 'üéâ';
    celebration.style.cssText = `
        position: fixed;
        top: 50%;
        left: 50%;
        transform: translate(-50%, -50%);
        font-size: 5em;
        z-index: 10000;
        animation: celebrate 1s ease-out forwards;
    `;
    
    const style = document.createElement('style');
    style.textContent = `
        @keyframes celebrate {
            0% { transform: translate(-50%, -50%) scale(0); opacity: 1; }
            50% { transform: translate(-50%, -50%) scale(1.2); }
            100% { transform: translate(-50%, -50%) scale(1) translateY(-100px); opacity: 0; }
        }
    `;
    
    document.head.appendChild(style);
    document.body.appendChild(celebration);
    
    setTimeout(() => {
        celebration.remove();
        style.remove();
    }, 1000);
}

// ==================== QUIZ FUNCTIONS ====================
function loadFillInTheBlankQuiz() {
    const container = document.getElementById('fillQuizContainer');
    container.innerHTML = '';
    
    fillInTheBlankQuiz.forEach((q, index) => {
        const questionCard = document.createElement('div');
        questionCard.className = 'question-card';
        questionCard.dataset.index = index;
        
        const questionText = q.question.replace('_______', '<span style="color: #dc3545; font-weight: bold;">_______</span>');
        
        questionCard.innerHTML = `
            <div class="question-text">${index + 1}. ${questionText}</div>
            <div class="options-grid">
                ${q.options.map(opt => `
                    <button class="option-btn" onclick="selectFillOption(${index}, '${opt}', this)">${opt}</button>
                `).join('')}
            </div>
            <div class="feedback-container"></div>
        `;
        
        container.appendChild(questionCard);
    });
}

function selectFillOption(questionIndex, selectedAnswer, button) {
    const card = button.closest('.question-card');
    card.querySelectorAll('.option-btn').forEach(btn => {
        btn.classList.remove('selected');
    });
    button.classList.add('selected');
    card.dataset.selected = selectedAnswer;
    
    // Clear previous feedback
    const feedbackContainer = card.querySelector('.feedback-container');
    feedbackContainer.innerHTML = '';
}

function checkAllFillAnswers() {
    let correct = 0;
    fillInTheBlankQuiz.forEach((q, index) => {
        const card = document.querySelector(`#fillQuizContainer .question-card[data-index="${index}"]`);
        const selected = card.dataset.selected;
        const feedbackContainer = card.querySelector('.feedback-container');
        
        if (!selected) {
            feedbackContainer.innerHTML = '<div class="feedback incorrect">Please select an answer!</div>';
            return;
        }
        
        gameData.totalAnswers++;
        
        if (selected === q.answer) {
            correct++;
            gameData.correctAnswers++;
            gameData.streak++;
            gameData.points += 5;
            feedbackContainer.innerHTML = '<div class="feedback correct">‚úì Correct! Well done!</div>';
            card.querySelectorAll('.option-btn').forEach(btn => {
                if (btn.textContent === q.answer) {
                    btn.classList.add('correct');
                }
            });
        } else {
            gameData.streak = 0;
            feedbackContainer.innerHTML = `<div class="feedback incorrect">‚úó Incorrect. The correct answer is: <strong>${q.answer}</strong></div>`;
            card.querySelectorAll('.option-btn').forEach(btn => {
                if (btn.classList.contains('selected')) {
                    btn.classList.add('incorrect');
                }
                if (btn.textContent === q.answer) {
                    btn.classList.add('correct');
                }
            });
        }
    });
    
    updateGameStats();
    markSectionComplete('quiz-fill');
}

function loadTrueFalseQuiz() {
    const container = document.getElementById('tfQuizContainer');
    container.innerHTML = '';
    
    trueFalseQuiz.forEach((q, index) => {
        const questionCard = document.createElement('div');
        questionCard.className = 'question-card';
        questionCard.dataset.index = index;
        
        questionCard.innerHTML = `
            <div class="question-text">${index + 1}. ${q.question}</div>
            <div class="options-grid">
                <button class="option-btn" onclick="selectTFOption(${index}, true, this)">True</button>
                <button class="option-btn" onclick="selectTFOption(${index}, false, this)">False</button>
            </div>
            <div class="feedback-container"></div>
        `;
        
        container.appendChild(questionCard);
    });
}

function selectTFOption(questionIndex, selectedAnswer, button) {
    const card = button.closest('.question-card');
    card.querySelectorAll('.option-btn').forEach(btn => {
        btn.classList.remove('selected');
    });
    button.classList.add('selected');
    card.dataset.selected = selectedAnswer;
    
    // Clear previous feedback
    const feedbackContainer = card.querySelector('.feedback-container');
    feedbackContainer.innerHTML = '';
}

function checkAllTFAnswers() {
    let correct = 0;
    trueFalseQuiz.forEach((q, index) => {
        const card = document.querySelector(`#tfQuizContainer .question-card[data-index="${index}"]`);
        const selected = card.dataset.selected;
        const feedbackContainer = card.querySelector('.feedback-container');
        
        if (selected === undefined) {
            feedbackContainer.innerHTML = '<div class="feedback incorrect">Please select an answer!</div>';
            return;
        }
        
        gameData.totalAnswers++;
        const selectedBool = selected === 'true';
        
        if (selectedBool === q.answer) {
            correct++;
            gameData.correctAnswers++;
            gameData.streak++;
            gameData.points += 5;
            feedbackContainer.innerHTML = '<div class="feedback correct">‚úì Correct!</div>';
            card.querySelectorAll('.option-btn').forEach(btn => {
                if (btn.classList.contains('selected')) {
                    btn.classList.add('correct');
                }
            });
        } else {
            gameData.streak = 0;
            const correctAnswer = q.answer ? 'True' : 'False';
            feedbackContainer.innerHTML = `<div class="feedback incorrect">‚úó Incorrect. The correct answer is: <strong>${correctAnswer}</strong></div>`;
            card.querySelectorAll('.option-btn').forEach(btn => {
                if (btn.classList.contains('selected')) {
                    btn.classList.add('incorrect');
                }
                if ((btn.textContent === 'True' && q.answer) || (btn.textContent === 'False' && !q.answer)) {
                    btn.classList.add('correct');
                }
            });
        }
    });
    
    updateGameStats();
    markSectionComplete('quiz-tf');
}

function loadMultipleChoiceQuiz() {
    const container = document.getElementById('mcQuizContainer');
    container.innerHTML = '';
    
    multipleChoiceQuiz.forEach((q, index) => {
        const questionCard = document.createElement('div');
        questionCard.className = 'question-card';
        questionCard.dataset.index = index;
        
        questionCard.innerHTML = `
            <div class="question-text">${index + 1}. ${q.question}</div>
            <div class="options-grid">
                ${q.options.map(opt => `
                    <button class="option-btn" onclick="selectMCOption(${index}, '${opt.replace(/'/g, "\\'")}', this)">${opt}</button>
                `).join('')}
            </div>
            <div class="feedback-container"></div>
        `;
        
        container.appendChild(questionCard);
    });
}

function selectMCOption(questionIndex, selectedAnswer, button) {
    const card = button.closest('.question-card');
    card.querySelectorAll('.option-btn').forEach(btn => {
        btn.classList.remove('selected');
    });
    button.classList.add('selected');
    card.dataset.selected = selectedAnswer;
    
    // Clear previous feedback
    const feedbackContainer = card.querySelector('.feedback-container');
    feedbackContainer.innerHTML = '';
}

function checkAllMCAnswers() {
    let correct = 0;
    multipleChoiceQuiz.forEach((q, index) => {
        const card = document.querySelector(`#mcQuizContainer .question-card[data-index="${index}"]`);
        const selected = card.dataset.selected;
        const feedbackContainer = card.querySelector('.feedback-container');
        
        if (!selected) {
            feedbackContainer.innerHTML = '<div class="feedback incorrect">Please select an answer!</div>';
            return;
        }
        
        gameData.totalAnswers++;
        
        if (selected === q.answer) {
            correct++;
            gameData.correctAnswers++;
            gameData.streak++;
            gameData.points += 5;
            feedbackContainer.innerHTML = '<div class="feedback correct">‚úì Excellent! That\'s correct!</div>';
            card.querySelectorAll('.option-btn').forEach(btn => {
                if (btn.textContent === q.answer) {
                    btn.classList.add('correct');
                }
            });
        } else {
            gameData.streak = 0;
            feedbackContainer.innerHTML = `<div class="feedback incorrect">‚úó Incorrect. The correct answer is: <strong>${q.answer}</strong></div>`;
            card.querySelectorAll('.option-btn').forEach(btn => {
                if (btn.classList.contains('selected')) {
                    btn.classList.add('incorrect');
                }
                if (btn.textContent === q.answer) {
                    btn.classList.add('correct');
                }
            });
        }
    });
    
    updateGameStats();
    markSectionComplete('quiz-mc');
}

function showFinalResults() {
    const accuracy = gameData.totalAnswers > 0 
        ? Math.round((gameData.correctAnswers / gameData.totalAnswers) * 100) 
        : 0;
    
    let grade = '';
    let message = '';
    let emoji = '';
    
    if (accuracy >= 90) {
        grade = 'A+';
        message = 'Outstanding! You\'ve mastered Transformers!';
        emoji = 'üèÜ';
    } else if (accuracy >= 80) {
        grade = 'A';
        message = 'Excellent work! You have a strong understanding!';
        emoji = 'üåü';
    } else if (accuracy >= 70) {
        grade = 'B';
        message = 'Good job! Keep practicing to improve!';
        emoji = 'üëç';
    } else if (accuracy >= 60) {
        grade = 'C';
        message = 'You\'re getting there! Review the material and try again!';
        emoji = 'üìö';
    } else {
        grade = 'D';
        message = 'Keep studying! Go back and review the content!';
        emoji = 'üí™';
    }
    
    const modal = document.createElement('div');
    modal.style.cssText = `
        position: fixed;
        top: 0;
        left: 0;
        right: 0;
        bottom: 0;
        background: rgba(0,0,0,0.8);
        display: flex;
        justify-content: center;
        align-items: center;
        z-index: 10000;
        animation: fadeIn 0.3s;
    `;
    
    modal.innerHTML = `
        <div style="background: white; padding: 40px; border-radius: 20px; text-align: center; max-width: 500px; animation: slideUp 0.3s;">
            <div style="font-size: 5em; margin-bottom: 20px;">${emoji}</div>
            <h2 style="color: #667eea; margin-bottom: 20px;">Final Results</h2>
            <div style="font-size: 4em; font-weight: bold; color: #667eea; margin: 20px 0;">${grade}</div>
            <p style="font-size: 1.2em; 
        margin-bottom: 30px; 
        color: #333;
    ">${message}</p>
            <div style="font-size: 1.1em; color: #555; margin-bottom: 30px;">
                <p><strong>Total Points:</strong> ${gameData.points} üèÜ</p>
                <p><strong>Final Accuracy:</strong> ${accuracy}% üéØ</p>
            </div>
            <button 
                class="action-btn primary" 
                onclick="this.closest('div[style*=\'position: fixed\']').remove()"
            >Close</button>
        </div>
    `;
    
    // Add animations and append to body
    const style = document.createElement('style');
    style.textContent = `
        @keyframes fadeIn { from { opacity: 0; } to { opacity: 1; } }
        @keyframes slideUp { from { transform: translateY(50px); opacity: 0; } to { transform: translateY(0); opacity: 1; } }
    `;
    
    document.head.appendChild(style);
    document.body.appendChild(modal);
    
    // Clean up style tag
    setTimeout(() => {
        style.remove();
    }, 300);
}


// ==================== INITIALIZATION ====================
document.addEventListener('DOMContentLoaded', () => {
    // Setup tab navigation
    const tabs = document.querySelectorAll('.tab-btn');
    tabs.forEach(tab => {
        tab.addEventListener('click', () => navigateToTab(tab.dataset.tab));
    });

    // Setup glossary accordion
    const accordionHeaders = document.querySelectorAll('.accordion-header');
    accordionHeaders.forEach(header => {
        header.addEventListener('click', () => {
            const content = header.nextElementSibling;
            header.classList.toggle('active');
            content.classList.toggle('active');
        });
    });

    // Load all quizzes on page load
    loadFillInTheBlankQuiz();
    loadTrueFalseQuiz();
    loadMultipleChoiceQuiz();
    
    // Initialize the game stats display
    updateGameStats();
});
</script>
</body>
</html>
